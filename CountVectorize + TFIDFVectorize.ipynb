{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "코싸인유사도적용.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungyeon38/Webtoon_recommendation_system/blob/master/CountVectorize%20%2B%20TFIDFVectorize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J3HzhmAim89R"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AEKymwhWxV",
        "outputId": "6b50e56c-c95f-473a-e52b-1cc68d214334"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "string.punctuation\n",
        "from math import log\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from gensim.summarization import keywords\n",
        "from textblob import TextBlob\n",
        "\n",
        "!pip install gensim\n",
        "!pip install konlpy"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBTfyqehdID"
      },
      "source": [
        "comic = pd.read_csv('./sample_data/Webtoon Dataset.csv')"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_comic = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjOwaO2zv0sW",
        "outputId": "ded5a6c0-3c47-476c-e59b-63f106546e95"
      },
      "execution_count": 205,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Death of a Pop Star\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " selected_comic = comic.loc[(comic.Name == input_comic)]\n",
        "\n",
        " print(selected_comic['Name'])"
      ],
      "metadata": {
        "id": "7UunDt7dvtYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218c8715-7c96-4cb9-cef5-8740db30fd5c"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30    Death of a Pop Star\n",
            "Name: Name, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsmb3sHGhdev"
      },
      "source": [
        "# 축약형 \n",
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"she's\": \"she is\"}\n",
        "\n",
        "def regularize_contractions(text):\n",
        "\n",
        "    contractionfree_list = []\n",
        "    \n",
        "    for word in text.split(\" \"):\n",
        "      if word in contractions.keys():\n",
        "        contractionfree_list.append(contractions[word])\n",
        "      else :\n",
        "        contractionfree_list.append(word)\n",
        "      \n",
        "    return \" \".join(contractionfree_list)\n"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpeOq8H5WV_"
      },
      "source": [
        "#defining the function to remove punctuation\n",
        "# 글자가 puctuation에 해당하면 \" \"를, 해당하지 않으면 글자 그대로\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree_list = []\n",
        "\n",
        "    for word in text:\n",
        "      if word in string.punctuation:\n",
        "        punctuationfree_list.append(\" \")\n",
        "      else :\n",
        "        punctuationfree_list.append(word)\n",
        "    return \"\".join(punctuationfree_list)\n",
        "\n",
        "\n",
        "# def remove_punctuation(text):\n",
        "#     punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
        "#     return punctuationfree"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_YijrK_flsD"
      },
      "source": [
        "# #defining function for tokenization\n",
        "# 숫자 포함 토큰화\n",
        "# def tokenization(text):\n",
        "#     tokens = re.split('\\W+', text)\n",
        "\n",
        "#     return tokens\n",
        "\n",
        "# 영어만 단어단위로 토큰화\n",
        "p = re.compile('[a-z]+')\n",
        "\n",
        "def tokenization(text):\n",
        "    # print(text)\n",
        "    result = p.findall(text)\n",
        "    # print(result)\n",
        "    return result"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t9lmVILpJ5J"
      },
      "source": [
        "#stop words present in the library\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "# print(stopwords[:20]) \n",
        "\n",
        "#defining the function to remove stopwords from tokenized text\n",
        "# stopwords 제거 \n",
        "def remove_stopwords(text):\n",
        "    for word in text:\n",
        "      output= [word for word in text if word not in stopwords]\n",
        "    return output"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsyAbTHb5Wl",
        "outputId": "7af73d84-b211-4944-fc7b-247588c5d9db"
      },
      "source": [
        "#setting lower case\n",
        "comic['Lower_Summary'] = comic['Summary'].apply(lambda x: x.lower())\n",
        "comic['Lower_Summary'].head(3)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she's young, single and about to achieve her d...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Lower_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ksxt3pIkA7O",
        "outputId": "7892a201-3668-4876-9088-58baf39abafe"
      },
      "source": [
        "comic['No_Contraction_Summary'] = comic['Lower_Summary'].apply(lambda x:regularize_contractions(x))\n",
        "comic['No_Contraction_Summary'].head(3)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young, single and about to achieve her ...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: No_Contraction_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6dBD6jokDNl",
        "outputId": "94fa9db7-0383-4970-950d-5c2f2df8a9ee"
      },
      "source": [
        "comic['Clean_Summary'] = comic['No_Contraction_Summary'].apply(lambda x:remove_punctuation(x))\n",
        "comic['Clean_Summary'].head(3)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young  single and about to achieve her ...\n",
              "1    after binge watching beauty videos online  a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Clean_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu8IBMAomStz",
        "outputId": "6e4de9ae-927f-47e4-ac96-29ae35f408a2"
      },
      "source": [
        "#applying function to the column\n",
        "comic['Tokenied_Summary'] = comic['Clean_Summary'].apply(lambda x: tokenization(x))\n",
        "\n",
        "comic['Tokenied_Summary'].head(3)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [she, is, young, single, and, about, to, achie...\n",
              "1    [after, binge, watching, beauty, videos, onlin...\n",
              "2    [after, making, a, grisly, discovery, in, the,...\n",
              "Name: Tokenied_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CpN1ehSdabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf4d5bd-d84a-4599-f6cc-8d21247a5505"
      },
      "source": [
        "#applying the function\n",
        "comic['No_Stopwords_Summary'] = comic['Tokenied_Summary'].apply(lambda x:remove_stopwords(x))\n",
        "\n",
        "comic['No_Stopwords_Summary'].head(3)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, creating, incr...\n",
              "1    [binge, watching, beauty, videos, online, shy,...\n",
              "2    [making, grisly, discovery, countryside, small...\n",
              "Name: No_Stopwords_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_no_verb(text):\n",
        "  part_of_speech_text = pos_tag(text)\n",
        "  result = []\n",
        "  for word in part_of_speech_text:\n",
        "    if word[1] != \"VB\" and word[1] != \"VBD\" and word[1] != \"VBG\" and word[1] != \"VBN\" and word[1] != \"VBP\" and word[1] != \"VBZ\":\n",
        "        result.append(word[0])\n",
        "  return result; \n",
        "\n",
        "comic['No_Verb_Summary'] = comic['No_Stopwords_Summary'].apply(lambda x:extract_no_verb(x))\n",
        "\n",
        "comic['No_Verb_Summary'].head(3)"
      ],
      "metadata": {
        "id": "4LON9acgf0xx",
        "outputId": "e6e1853c-47e5-46c6-a066-fbf81ea06352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, incredible, vi...\n",
              "1    [binge, beauty, videos, online, shy, comic, bo...\n",
              "2    [grisly, discovery, countryside, small, town, ...\n",
              "Name: No_Verb_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqFR0C4gddRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5ec521-878f-4d16-943d-236dd5dd5913"
      },
      "source": [
        "# df1 = comic['No_Stopwords_Summary']\n",
        "# doc_words_list = df1.values.tolist()\n",
        "\n",
        "# print(doc_words_list)\n",
        "\n",
        "\n",
        "def wordlist_to_string(words_list) :\n",
        "  doc = []\n",
        "  for doc_word in words_list :\n",
        "    doc.append(doc_word)\n",
        "  return \" \".join(doc)\n",
        "\n",
        "\n",
        "#comic['Summary_final'] = comic['Stemmed_Summary'].apply(lambda x:wordlist_to_string(x))\n",
        "comic['Summary_final'] = comic['No_Verb_Summary'].apply(lambda x:wordlist_to_string(x))\n",
        "\n",
        "comic['Summary_final'].head(3)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    young single achieve dream creating incredible...\n",
              "1    binge watching beauty videos online shy comic ...\n",
              "2    making grisly discovery countryside small town...\n",
              "Name: Summary_final, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW6gJoIYxfhl"
      },
      "source": [
        "def extract_keywords(doc):\n",
        "  keyword_list = []\n",
        "  keyword_string = keywords(doc)\n",
        "  keyword_list = keyword_string.split('\\n')\n",
        "\n",
        "  return keyword_list;\n",
        "\n",
        "\n",
        "comic['Summary_Keywords'] = comic['Summary_final'].apply(lambda x:extract_keywords(x))"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_3(keyword_list):\n",
        "  keyword_list_3 = keyword_list[0:3]\n",
        "\n",
        "  return keyword_list_3\n",
        "\n",
        "comic['Summary_Keywords_3'] = comic['Summary_Keywords'].apply(lambda x:keyword_3(x))\n",
        "\n",
        "comic.head(10)"
      ],
      "metadata": {
        "id": "xg6fXrcZtCV3",
        "outputId": "98c6a95b-4d7b-476b-ff39-7d7a28cb7907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Subscribers</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Update</th>\n",
              "      <th>Reading Link</th>\n",
              "      <th>Lower_Summary</th>\n",
              "      <th>No_Contraction_Summary</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Tokenied_Summary</th>\n",
              "      <th>No_Stopwords_Summary</th>\n",
              "      <th>No_Verb_Summary</th>\n",
              "      <th>Summary_final</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>30.6M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>4.2M</td>\n",
              "      <td>She's young, single and about to achieve her d...</td>\n",
              "      <td>UP EVERY TUESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/letsplay/l...</td>\n",
              "      <td>she's young, single and about to achieve her d...</td>\n",
              "      <td>she is young, single and about to achieve her ...</td>\n",
              "      <td>she is young  single and about to achieve her ...</td>\n",
              "      <td>[she, is, young, single, and, about, to, achie...</td>\n",
              "      <td>[young, single, achieve, dream, creating, incr...</td>\n",
              "      <td>[young, single, achieve, dream, incredible, vi...</td>\n",
              "      <td>young single achieve dream creating incredible...</td>\n",
              "      <td>[game, gaming, popular streamer, life, single,...</td>\n",
              "      <td>[game, gaming, popular streamer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True Beauty</td>\n",
              "      <td>Yaongyi</td>\n",
              "      <td>39.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>6.4M</td>\n",
              "      <td>After binge-watching beauty videos online, a s...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/truebeauty...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge watching beauty videos online  a s...</td>\n",
              "      <td>[after, binge, watching, beauty, videos, onlin...</td>\n",
              "      <td>[binge, watching, beauty, videos, online, shy,...</td>\n",
              "      <td>[binge, beauty, videos, online, shy, comic, bo...</td>\n",
              "      <td>binge watching beauty videos online shy comic ...</td>\n",
              "      <td>[secret, prettiest, watching, standing, short ...</td>\n",
              "      <td>[secret, prettiest, watching]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Midnight Poppy Land</td>\n",
              "      <td>Lilydusk</td>\n",
              "      <td>10.4M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.81</td>\n",
              "      <td>2.1M</td>\n",
              "      <td>After making a grisly discovery in the country...</td>\n",
              "      <td>UP EVERY SATURDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/midnight-p...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>[after, making, a, grisly, discovery, in, the,...</td>\n",
              "      <td>[making, grisly, discovery, countryside, small...</td>\n",
              "      <td>[grisly, discovery, countryside, small, town, ...</td>\n",
              "      <td>making grisly discovery countryside small town...</td>\n",
              "      <td>[underworld, takes, intimidating, grisly]</td>\n",
              "      <td>[underworld, takes, intimidating]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Age Matters</td>\n",
              "      <td>Enjelicious</td>\n",
              "      <td>25.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.79</td>\n",
              "      <td>3.5M</td>\n",
              "      <td>She's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/age-matter...</td>\n",
              "      <td>she's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30's...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30 s...</td>\n",
              "      <td>[she, is, a, hopeless, romantic, who, is, turn...</td>\n",
              "      <td>[hopeless, romantic, turning, super, happy, re...</td>\n",
              "      <td>[hopeless, romantic, super, happy, reclusive, ...</td>\n",
              "      <td>hopeless romantic turning super happy reclusiv...</td>\n",
              "      <td>[happy, rules, way]</td>\n",
              "      <td>[happy, rules, way]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Unholy Blood</td>\n",
              "      <td>Lina Im / Jeonghyeon Kim</td>\n",
              "      <td>9.9M</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.85</td>\n",
              "      <td>1.5M</td>\n",
              "      <td>When vampires destroy her chance to have the n...</td>\n",
              "      <td>UP EVERY THURSDAY</td>\n",
              "      <td>https://www.webtoons.com/en/supernatural/unhol...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>[when, vampires, destroy, her, chance, to, hav...</td>\n",
              "      <td>[vampires, destroy, chance, normal, life, alwa...</td>\n",
              "      <td>[vampires, chance, normal, life, always, hayan...</td>\n",
              "      <td>vampires destroy chance normal life always wan...</td>\n",
              "      <td>[hayan forced, force, destroy chance normal]</td>\n",
              "      <td>[hayan forced, force, destroy chance normal]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LUMINE</td>\n",
              "      <td>Emma Krogell</td>\n",
              "      <td>18.9M</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.82</td>\n",
              "      <td>3M</td>\n",
              "      <td>A runaway werewolf, Lumine, meets a witch boy ...</td>\n",
              "      <td>UP EVERY SUNDAY</td>\n",
              "      <td>https://www.webtoons.com/en/fantasy/lumine/lis...</td>\n",
              "      <td>a runaway werewolf, lumine, meets a witch boy ...</td>\n",
              "      <td>a runaway werewolf, lumine, meets a witch boy ...</td>\n",
              "      <td>a runaway werewolf  lumine  meets a witch boy ...</td>\n",
              "      <td>[a, runaway, werewolf, lumine, meets, a, witch...</td>\n",
              "      <td>[runaway, werewolf, lumine, meets, witch, boy,...</td>\n",
              "      <td>[runaway, werewolf, lumine, meets, boy, kody, ...</td>\n",
              "      <td>runaway werewolf lumine meets witch boy named ...</td>\n",
              "      <td>[kody, lumine, unfortunate, try]</td>\n",
              "      <td>[kody, lumine, unfortunate]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Jackson's Diary</td>\n",
              "      <td>Paola Batalla</td>\n",
              "      <td>2.9M</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.66</td>\n",
              "      <td>649K</td>\n",
              "      <td>The year is 1989, and Jackson is starting his ...</td>\n",
              "      <td>UP EVERY SUNDAY</td>\n",
              "      <td>https://www.webtoons.com/en/supernatural/jacks...</td>\n",
              "      <td>the year is 1989, and jackson is starting his ...</td>\n",
              "      <td>the year is 1989, and jackson is starting his ...</td>\n",
              "      <td>the year is 1989  and jackson is starting his ...</td>\n",
              "      <td>[the, year, is, and, jackson, is, starting, hi...</td>\n",
              "      <td>[year, jackson, starting, senior, year, brand,...</td>\n",
              "      <td>[year, jackson, senior, year, brand, new, scho...</td>\n",
              "      <td>year jackson starting senior year brand new sc...</td>\n",
              "      <td>[new, feeling, starts feel, starting, year]</td>\n",
              "      <td>[new, feeling, starts feel]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Teenage Mercenary</td>\n",
              "      <td>YC / Rakyeon</td>\n",
              "      <td>9,29,796</td>\n",
              "      <td>Action</td>\n",
              "      <td>9.87</td>\n",
              "      <td>537.6K</td>\n",
              "      <td>At the age of eight, Ijin Yu lost his parents ...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/action/teenage-mer...</td>\n",
              "      <td>at the age of eight, ijin yu lost his parents ...</td>\n",
              "      <td>at the age of eight, ijin yu lost his parents ...</td>\n",
              "      <td>at the age of eight  ijin yu lost his parents ...</td>\n",
              "      <td>[at, the, age, of, eight, ijin, yu, lost, his,...</td>\n",
              "      <td>[age, eight, ijin, yu, lost, parents, plane, c...</td>\n",
              "      <td>[age, eight, ijin, yu, parents, plane, crash, ...</td>\n",
              "      <td>age eight ijin yu lost parents plane crash bec...</td>\n",
              "      <td>[survival, survive, ijin, school, years, year,...</td>\n",
              "      <td>[survival, survive, ijin]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Nice To Meet You</td>\n",
              "      <td>Wishroomness</td>\n",
              "      <td>5.8M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.82</td>\n",
              "      <td>1.1M</td>\n",
              "      <td>A ditsy university student Mew finds a lost st...</td>\n",
              "      <td>UP EVERY MONDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/nice-to-me...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>[a, ditsy, university, student, mew, finds, a,...</td>\n",
              "      <td>[ditsy, university, student, mew, finds, lost,...</td>\n",
              "      <td>[ditsy, university, student, mew, student, car...</td>\n",
              "      <td>ditsy university student mew finds lost studen...</td>\n",
              "      <td>[life, card, student mew, little]</td>\n",
              "      <td>[life, card, student mew]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>I Love Yoo</td>\n",
              "      <td>Quimchee</td>\n",
              "      <td>29M</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.78</td>\n",
              "      <td>4.3M</td>\n",
              "      <td>Dogged by pain and misfortune from the very be...</td>\n",
              "      <td>UP EVERY FRIDAY</td>\n",
              "      <td>https://www.webtoons.com/en/drama/i-love-yoo/l...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>[dogged, by, pain, and, misfortune, from, the,...</td>\n",
              "      <td>[dogged, pain, misfortune, beginning, shin, ae...</td>\n",
              "      <td>[pain, misfortune, shin, ae, decides, nothing,...</td>\n",
              "      <td>dogged pain misfortune beginning shin ae decid...</td>\n",
              "      <td>[pain misfortune beginning]</td>\n",
              "      <td>[pain misfortune beginning]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                            Summary_Keywords_3\n",
              "0   0  ...              [game, gaming, popular streamer]\n",
              "1   1  ...                 [secret, prettiest, watching]\n",
              "2   2  ...             [underworld, takes, intimidating]\n",
              "3   3  ...                           [happy, rules, way]\n",
              "4   4  ...  [hayan forced, force, destroy chance normal]\n",
              "5   5  ...                   [kody, lumine, unfortunate]\n",
              "6   6  ...                   [new, feeling, starts feel]\n",
              "7   7  ...                     [survival, survive, ijin]\n",
              "8   8  ...                     [life, card, student mew]\n",
              "9   9  ...                   [pain misfortune beginning]\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence = []\n",
        "#for user_sentence in comic['No_Verb_Summary'].values:\n",
        "#  sentence.append(list(map(str, user_sentence)))"
      ],
      "metadata": {
        "id": "rm4xKpSl-4oX"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from gensim import Word2Vec\n",
        "\n",
        "#embedding_model = Word2Vec(sentence, size = 20, window = 5, min_count = 2, workers = 4, iter = 300, sg = 1)\n"
      ],
      "metadata": {
        "id": "UbJl-2v-_x0D"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding_model.wv.most_similar(positive = comic[''], topn = 10)"
      ],
      "metadata": {
        "id": "13HL_psiBfM9"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#synsets(검색) -> 리스트\n",
        "\n",
        "#synset(신셋색인)  .definition() .examples()  .lemmas()  .hyponyms()\n",
        "# wordnet.synset('young.a.01').definition()\n",
        "# wordnet.synset('beauty.n.01').hypernym_paths()\n",
        "# word_beautiful = wordnet.synset('beautiful.a.01')\n",
        "# word_pretty = wordnet.synset('pretty.a.01')\n",
        "# print(word_pretty.wup_similarity(word_beautiful))\n",
        "\n",
        "# dog = wordnet.synset('dog.n.01')\n",
        "# cat = wordnet.synset('cat.n.01')\n",
        "\n",
        "# print(dog.wup_similarity(cat))\n",
        "\n",
        "\n",
        "!pip install textblob\n",
        "\n",
        "\n",
        "# pos_tag([\"beauty\"])\n",
        "\n",
        "# wordnet.synset('car.n.01').definition() wordnet.synset('car.n.01').examples() wordnet.synset('car.n.01').lemmas()\n",
        "\n",
        "# comic['Summary_Keywords_3'] = comic['Summary_Keywords'].apply(lambda x:keyword_3(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuxt5l5o_BB",
        "outputId": "85c2bfa3-26e9-41ba-c68a-1622035dc6af"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# word = Word(\"beauty\")\n",
        "# print(word.synsets)\n",
        "\n",
        "def keyword_synsets(keywords):\n",
        "  keyword_synsets = []\n",
        "  for i in range(len(keywords)):\n",
        "    keyword_synsets.append(keywords[i])\n",
        "    word = Word(keywords[i])\n",
        "    for synset in word.synsets:\n",
        "      for lemma in synset.lemmas():\n",
        "        if lemma.name() not in keyword_synsets:\n",
        "          keyword_synsets.append(lemma.name())\n",
        "\n",
        "  return keyword_synsets\n",
        "\n",
        "\n",
        "comic['Summary_Keywords_Synsets'] = comic['Summary_Keywords'].apply(lambda x:keyword_synsets(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H6EGbjORSNJ",
        "outputId": "a76489f5-0289-489a-dfb3-c20b23feb1dd"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comic['Summary_Keywords'].head(1)\n",
        "comic['Summary_Keywords_Synsets'].head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yf4ESd4Zck6",
        "outputId": "b8b6eeea-4cb0-4e31-a7f7-c222fdc89202"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [game, plot, secret_plan, biz, bet_on, back, g...\n",
              "Name: Summary_Keywords_Synsets, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "jYpGYoX32BpS",
        "outputId": "80925af5-f4c2-45fa-f46d-6d90f2425ce6"
      },
      "source": [
        "comic_df = comic[['id','Name', 'Writer', 'Genre', 'Rating', 'Summary_Keywords',\n",
        "                 'Summary_Keywords_3', 'Summary_Keywords_Synsets']]\n",
        "# comic_df = comic[['id','Name', 'Writer', 'Genre', 'Rating', 'Summary_Keywords']]\n",
        "comic_df.head(1)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[game, gaming, popular streamer, life, single,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id        Name  ... Rating                                   Summary_Keywords\n",
              "0   0  Let's Play  ...   9.62  [game, gaming, popular streamer, life, single,...\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "# comic_df['Summary_literal'] = comic_df['Summary_Keywords'].apply(lambda x : (' ').join(x))\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vect.fit_transform(comic_df['Summary_literal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08JTng0NxTGD",
        "outputId": "d30aa1da-27f3-4480-b3e4-7648867b183c"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim_tfidf = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVTfAXLMzngT",
        "outputId": "ccf4fbc0-b211-4034-f912-067dc1e46c86"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comic_tfidf_REC(title, cosine_sim=cosine_sim_tfidf):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_tfidf_REC(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "OcjfNf6W0rPW",
        "outputId": "d8bcea9a-597f-4a43-b476-bef65ec381d5"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>Oh! Holy</td>\n",
              "      <td>Ahyun</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.70</td>\n",
              "      <td>[invisible, takes, school, remain]</td>\n",
              "      <td>invisible takes school remain</td>\n",
              "      <td>0.226544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>Gourmet Hound</td>\n",
              "      <td>Leehama</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.82</td>\n",
              "      <td>[taste, loved years lucky accident, woman]</td>\n",
              "      <td>taste loved years lucky accident woman</td>\n",
              "      <td>0.205367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Midnight Poppy Land</td>\n",
              "      <td>Lilydusk</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.81</td>\n",
              "      <td>[underworld, takes, intimidating, grisly]</td>\n",
              "      <td>underworld takes intimidating grisly</td>\n",
              "      <td>0.205085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>249</td>\n",
              "      <td>Nomads</td>\n",
              "      <td>Captain Juuter</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.85</td>\n",
              "      <td>[nomads, nomad, turn, turns, starts, start, la...</td>\n",
              "      <td>nomads nomad turn turns starts start lance spe...</td>\n",
              "      <td>0.138702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[game, gaming, popular streamer, life, single,...</td>\n",
              "      <td>game gaming popular streamer life single finds</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True Beauty</td>\n",
              "      <td>Yaongyi</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>[secret, prettiest, watching, standing, short ...</td>\n",
              "      <td>secret prettiest watching standing short lived</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Age Matters</td>\n",
              "      <td>Enjelicious</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.79</td>\n",
              "      <td>[happy, rules, way]</td>\n",
              "      <td>happy rules way</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Unholy Blood</td>\n",
              "      <td>Lina Im / Jeonghyeon Kim</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.85</td>\n",
              "      <td>[hayan forced, force, destroy chance normal]</td>\n",
              "      <td>hayan forced force destroy chance normal</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LUMINE</td>\n",
              "      <td>Emma Krogell</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.82</td>\n",
              "      <td>[kody, lumine, unfortunate, try]</td>\n",
              "      <td>kody lumine unfortunate try</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Jackson's Diary</td>\n",
              "      <td>Paola Batalla</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.66</td>\n",
              "      <td>[new, feeling, starts feel, starting, year]</td>\n",
              "      <td>new feeling starts feel starting year</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "104  104  ...  0.226544\n",
              "101  101  ...  0.205367\n",
              "2      2  ...  0.205085\n",
              "249  249  ...  0.138702\n",
              "0      0  ...  0.000000\n",
              "1      1  ...  0.000000\n",
              "3      3  ...  0.000000\n",
              "4      4  ...  0.000000\n",
              "5      5  ...  0.000000\n",
              "6      6  ...  0.000000\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
        "count_matrix = count_vect.fit_transform(comic_df['Summary_literal'])\n",
        "print(count_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW8Y2divgNco",
        "outputId": "eae0b580-6802-413a-91a0-84303e20f872"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 3817)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_sim_count = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9C3jVWQgQIO",
        "outputId": "5c6f0284-bfd4-478d-cf38-08d811f54890"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comic_count_REC(title, cosine_sim=cosine_sim_count):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_count_REC(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "v_Vv6COshG8J",
        "outputId": "d3f4c770-5d30-4854-9372-56cb5d0a59b3"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Midnight Poppy Land</td>\n",
              "      <td>Lilydusk</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.81</td>\n",
              "      <td>[underworld, takes, intimidating, grisly]</td>\n",
              "      <td>underworld takes intimidating grisly</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>Oh! Holy</td>\n",
              "      <td>Ahyun</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.70</td>\n",
              "      <td>[invisible, takes, school, remain]</td>\n",
              "      <td>invisible takes school remain</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>Gourmet Hound</td>\n",
              "      <td>Leehama</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.82</td>\n",
              "      <td>[taste, loved years lucky accident, woman]</td>\n",
              "      <td>taste loved years lucky accident woman</td>\n",
              "      <td>0.113961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>249</td>\n",
              "      <td>Nomads</td>\n",
              "      <td>Captain Juuter</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.85</td>\n",
              "      <td>[nomads, nomad, turn, turns, starts, start, la...</td>\n",
              "      <td>nomads nomad turn turns starts start lance spe...</td>\n",
              "      <td>0.086711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[game, gaming, popular streamer, life, single,...</td>\n",
              "      <td>game gaming popular streamer life single finds</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True Beauty</td>\n",
              "      <td>Yaongyi</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>[secret, prettiest, watching, standing, short ...</td>\n",
              "      <td>secret prettiest watching standing short lived</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Age Matters</td>\n",
              "      <td>Enjelicious</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.79</td>\n",
              "      <td>[happy, rules, way]</td>\n",
              "      <td>happy rules way</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Unholy Blood</td>\n",
              "      <td>Lina Im / Jeonghyeon Kim</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.85</td>\n",
              "      <td>[hayan forced, force, destroy chance normal]</td>\n",
              "      <td>hayan forced force destroy chance normal</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LUMINE</td>\n",
              "      <td>Emma Krogell</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.82</td>\n",
              "      <td>[kody, lumine, unfortunate, try]</td>\n",
              "      <td>kody lumine unfortunate try</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Jackson's Diary</td>\n",
              "      <td>Paola Batalla</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.66</td>\n",
              "      <td>[new, feeling, starts feel, starting, year]</td>\n",
              "      <td>new feeling starts feel starting year</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "2      2  ...  0.142857\n",
              "104  104  ...  0.142857\n",
              "101  101  ...  0.113961\n",
              "249  249  ...  0.086711\n",
              "0      0  ...  0.000000\n",
              "1      1  ...  0.000000\n",
              "3      3  ...  0.000000\n",
              "4      4  ...  0.000000\n",
              "5      5  ...  0.000000\n",
              "6      6  ...  0.000000\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    }
  ]
}