{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CountVectorize + TFIDFVectorize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungyeon38/Webtoon_recommendation_system/blob/master/CountVectorize%20%2B%20TFIDFVectorize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J3HzhmAim89R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ed37e3-1340-4550-f393-5d27654a4457"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AEKymwhWxV",
        "outputId": "85154157-7088-42fb-e4e2-0b8d3d405799"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "string.punctuation\n",
        "from math import log\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from gensim.summarization import keywords\n",
        "from textblob import TextBlob\n",
        "\n",
        "!pip install gensim\n",
        "!pip install konlpy"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBTfyqehdID"
      },
      "source": [
        "comic = pd.read_csv('/content/drive/MyDrive/webtoon/Webtoon Dataset.csv')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_comic = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjOwaO2zv0sW",
        "outputId": "8670ebaf-698a-47a6-e4a4-a2eef0d62532"
      },
      "execution_count": 97,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Beauty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " selected_comic = comic.loc[(comic.Name == input_comic)]\n",
        "\n",
        " print(selected_comic['Name'])"
      ],
      "metadata": {
        "id": "7UunDt7dvtYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d758cc6-c80a-4c89-d9c6-68a8a50e03e0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    True Beauty\n",
            "Name: Name, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsmb3sHGhdev"
      },
      "source": [
        "# 축약형 \n",
        "\n",
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"she's\": \"she is\"}\n",
        "\n",
        "def regularize_contractions(text):\n",
        "\n",
        "    contractionfree_list = []\n",
        "    \n",
        "    for word in text.split(\" \"):\n",
        "      if word in contractions.keys():\n",
        "        contractionfree_list.append(contractions[word])\n",
        "      else :\n",
        "        contractionfree_list.append(word)\n",
        "      \n",
        "    return \" \".join(contractionfree_list)\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpeOq8H5WV_"
      },
      "source": [
        "# defining the function to remove punctuation\n",
        "# 글자가 puctuation에 해당하면 \" \"를, 해당하지 않으면 글자 그대로\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree_list = []\n",
        "\n",
        "    for word in text:\n",
        "      if word in string.punctuation:\n",
        "        punctuationfree_list.append(\" \")\n",
        "      else :\n",
        "        punctuationfree_list.append(word)\n",
        "    return \"\".join(punctuationfree_list)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_YijrK_flsD"
      },
      "source": [
        "# defining function for tokenization\n",
        "# 영어만 단어단위로 토큰화\n",
        "\n",
        "p = re.compile('[a-z]+')\n",
        "\n",
        "def tokenization(text):\n",
        "    # print(text)\n",
        "    result = p.findall(text)\n",
        "    # print(result)\n",
        "    return result"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t9lmVILpJ5J"
      },
      "source": [
        "# stop words present in the library\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# defining the function to remove stopwords from tokenized text\n",
        "# stopwords 제거 \n",
        "\n",
        "def remove_stopwords(text):\n",
        "    for word in text:\n",
        "      output= [word for word in text if word not in stopwords]\n",
        "    return output"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsyAbTHb5Wl",
        "outputId": "ca0163a1-927b-491b-a84c-7cbd5afe9193"
      },
      "source": [
        "# setting lower case\n",
        "\n",
        "comic['Lower_Summary'] = comic['Summary'].apply(lambda x: x.lower())\n",
        "comic['Lower_Summary'].head(3)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she's young, single and about to achieve her d...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Lower_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ksxt3pIkA7O",
        "outputId": "d5c34c87-0659-4a6b-e83f-13439e7820ee"
      },
      "source": [
        "# setting no contraction form\n",
        "\n",
        "comic['No_Contraction_Summary'] = comic['Lower_Summary'].apply(lambda x:regularize_contractions(x))\n",
        "comic['No_Contraction_Summary'].head(3)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young, single and about to achieve her ...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: No_Contraction_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6dBD6jokDNl",
        "outputId": "c8c439ba-eb02-488a-8022-c6ea50f185ad"
      },
      "source": [
        "# setting punctuation removed case\n",
        "\n",
        "comic['Clean_Summary'] = comic['No_Contraction_Summary'].apply(lambda x:remove_punctuation(x))\n",
        "comic['Clean_Summary'].head(3)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young  single and about to achieve her ...\n",
              "1    after binge watching beauty videos online  a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Clean_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu8IBMAomStz",
        "outputId": "635cfa6d-8bcc-4ab3-e642-26956a8d0a05"
      },
      "source": [
        "# Tokenize column\n",
        "\n",
        "comic['Tokenized_Summary'] = comic['Clean_Summary'].apply(lambda x: tokenization(x))\n",
        "comic['Tokenized_Summary'].head(3)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [she, is, young, single, and, about, to, achie...\n",
              "1    [after, binge, watching, beauty, videos, onlin...\n",
              "2    [after, making, a, grisly, discovery, in, the,...\n",
              "Name: Tokenized_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CpN1ehSdabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e07323d-78d7-4ad2-beed-cb20c13131ff"
      },
      "source": [
        "# remove Stopwords\n",
        "\n",
        "comic['No_Stopwords_Summary'] = comic['Tokenized_Summary'].apply(lambda x:remove_stopwords(x))\n",
        "comic['No_Stopwords_Summary'].head(3)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, creating, incr...\n",
              "1    [binge, watching, beauty, videos, online, shy,...\n",
              "2    [making, grisly, discovery, countryside, small...\n",
              "Name: No_Stopwords_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove verbs\n",
        "\n",
        "def extract_no_verb(text):\n",
        "  part_of_speech_text = pos_tag(text)\n",
        "  result = []\n",
        "  for word in part_of_speech_text:\n",
        "    if word[1] != \"VB\" and word[1] != \"VBD\" and word[1] != \"VBG\" and word[1] != \"VBN\" and word[1] != \"VBP\" and word[1] != \"VBZ\":\n",
        "        result.append(word[0])\n",
        "  return result; \n",
        "\n",
        "comic['No_Verb_Summary'] = comic['No_Stopwords_Summary'].apply(lambda x:extract_no_verb(x))\n",
        "comic['No_Verb_Summary'].head(3)"
      ],
      "metadata": {
        "id": "4LON9acgf0xx",
        "outputId": "3b4ad15a-3bc7-4571-d4e9-93afcc7014db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, incredible, vi...\n",
              "1    [binge, beauty, videos, online, shy, comic, bo...\n",
              "2    [grisly, discovery, countryside, small, town, ...\n",
              "Name: No_Verb_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqFR0C4gddRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9244edeb-28e7-4f17-d7e5-00a7903fb416"
      },
      "source": [
        "# make words to string\n",
        "\n",
        "def wordlist_to_string(words_list) :\n",
        "  doc = []\n",
        "  for doc_word in words_list :\n",
        "    doc.append(doc_word)\n",
        "  return \" \".join(doc)\n",
        "\n",
        "comic['Summary_final'] = comic['No_Verb_Summary'].apply(lambda x:wordlist_to_string(x))\n",
        "comic['Summary_final'].head(3)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    young single achieve dream incredible videogam...\n",
              "1    binge beauty videos online shy comic book fan ...\n",
              "2    grisly discovery countryside small town book e...\n",
              "Name: Summary_final, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW6gJoIYxfhl"
      },
      "source": [
        "# extract keywords using gensim\n",
        "\n",
        "def extract_keywords(doc):\n",
        "  keyword_list = []\n",
        "  keyword_string = keywords(doc)\n",
        "  keyword_list = keyword_string.split('\\n')\n",
        "\n",
        "  return keyword_list;\n",
        "\n",
        "comic['Summary_Keywords'] = comic['Summary_final'].apply(lambda x:extract_keywords(x))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract 3 important keywords\n",
        "\n",
        "def keyword_3(keyword_list):\n",
        "  keyword_list_3 = keyword_list[0:3]\n",
        "\n",
        "  return keyword_list_3\n",
        "\n",
        "comic['Summary_Keywords_3'] = comic['Summary_Keywords'].apply(lambda x:keyword_3(x))\n",
        "comic.head(5)"
      ],
      "metadata": {
        "id": "xg6fXrcZtCV3",
        "outputId": "065692a3-6b08-4504-923a-80a7a0ef9e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Subscribers</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Update</th>\n",
              "      <th>Reading Link</th>\n",
              "      <th>Lower_Summary</th>\n",
              "      <th>No_Contraction_Summary</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Tokenized_Summary</th>\n",
              "      <th>No_Stopwords_Summary</th>\n",
              "      <th>No_Verb_Summary</th>\n",
              "      <th>Summary_final</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>30.6M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>4.2M</td>\n",
              "      <td>She's young, single and about to achieve her d...</td>\n",
              "      <td>UP EVERY TUESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/letsplay/l...</td>\n",
              "      <td>she's young, single and about to achieve her d...</td>\n",
              "      <td>she is young, single and about to achieve her ...</td>\n",
              "      <td>she is young  single and about to achieve her ...</td>\n",
              "      <td>[she, is, young, single, and, about, to, achie...</td>\n",
              "      <td>[young, single, achieve, dream, creating, incr...</td>\n",
              "      <td>[young, single, achieve, dream, incredible, vi...</td>\n",
              "      <td>young single achieve dream incredible videogam...</td>\n",
              "      <td>[popular, videogames, single, troublesome, stay]</td>\n",
              "      <td>[popular, videogames, single]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True Beauty</td>\n",
              "      <td>Yaongyi</td>\n",
              "      <td>39.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>6.4M</td>\n",
              "      <td>After binge-watching beauty videos online, a s...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/truebeauty...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge watching beauty videos online  a s...</td>\n",
              "      <td>[after, binge, watching, beauty, videos, onlin...</td>\n",
              "      <td>[binge, watching, beauty, videos, online, shy,...</td>\n",
              "      <td>[binge, beauty, videos, online, shy, comic, bo...</td>\n",
              "      <td>binge beauty videos online shy comic book fan ...</td>\n",
              "      <td>[secret, status short, beauty videos]</td>\n",
              "      <td>[secret, status short, beauty videos]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Midnight Poppy Land</td>\n",
              "      <td>Lilydusk</td>\n",
              "      <td>10.4M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.81</td>\n",
              "      <td>2.1M</td>\n",
              "      <td>After making a grisly discovery in the country...</td>\n",
              "      <td>UP EVERY SATURDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/midnight-p...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>[after, making, a, grisly, discovery, in, the,...</td>\n",
              "      <td>[making, grisly, discovery, countryside, small...</td>\n",
              "      <td>[grisly, discovery, countryside, small, town, ...</td>\n",
              "      <td>grisly discovery countryside small town book e...</td>\n",
              "      <td>[deeper dangerous underworld]</td>\n",
              "      <td>[deeper dangerous underworld]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Age Matters</td>\n",
              "      <td>Enjelicious</td>\n",
              "      <td>25.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.79</td>\n",
              "      <td>3.5M</td>\n",
              "      <td>She's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/age-matter...</td>\n",
              "      <td>she's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30's...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30 s...</td>\n",
              "      <td>[she, is, a, hopeless, romantic, who, is, turn...</td>\n",
              "      <td>[hopeless, romantic, turning, super, happy, re...</td>\n",
              "      <td>[hopeless, romantic, super, happy, reclusive, ...</td>\n",
              "      <td>hopeless romantic super happy reclusive billio...</td>\n",
              "      <td>[happy, rules]</td>\n",
              "      <td>[happy, rules]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Unholy Blood</td>\n",
              "      <td>Lina Im / Jeonghyeon Kim</td>\n",
              "      <td>9.9M</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.85</td>\n",
              "      <td>1.5M</td>\n",
              "      <td>When vampires destroy her chance to have the n...</td>\n",
              "      <td>UP EVERY THURSDAY</td>\n",
              "      <td>https://www.webtoons.com/en/supernatural/unhol...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>[when, vampires, destroy, her, chance, to, hav...</td>\n",
              "      <td>[vampires, destroy, chance, normal, life, alwa...</td>\n",
              "      <td>[vampires, chance, normal, life, always, hayan...</td>\n",
              "      <td>vampires chance normal life always hayan draw ...</td>\n",
              "      <td>[hayan, chance normal, ones]</td>\n",
              "      <td>[hayan, chance normal, ones]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                     Summary_Keywords_3\n",
              "0   0  ...          [popular, videogames, single]\n",
              "1   1  ...  [secret, status short, beauty videos]\n",
              "2   2  ...          [deeper dangerous underworld]\n",
              "3   3  ...                         [happy, rules]\n",
              "4   4  ...           [hayan, chance normal, ones]\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# find and add synonym of keywords\n",
        "\n",
        "def keyword_synsets(keywords):\n",
        "  keyword_synsets = []\n",
        "  for i in range(len(keywords)):\n",
        "    keyword_synsets.append(keywords[i])\n",
        "    word = Word(keywords[i])\n",
        "    for synset in word.synsets:\n",
        "      for lemma in synset.lemmas():\n",
        "        if lemma.name() not in keyword_synsets:\n",
        "          keyword_synsets.append(lemma.name())\n",
        "\n",
        "  return keyword_synsets\n",
        "\n",
        "comic['Summary_Keywords_Synsets'] = comic['Summary_Keywords'].apply(lambda x:keyword_synsets(x))\n",
        "comic['Summary_Keywords_Synsets'].head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H6EGbjORSNJ",
        "outputId": "0a09cff1-bfb0-4e88-a3ac-a4cc09c46c48"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [popular, democratic, pop, videogames, single,...\n",
              "Name: Summary_Keywords_Synsets, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "jYpGYoX32BpS",
        "outputId": "b7ad545d-1965-4e53-bca5-96c4193f5c82"
      },
      "source": [
        "comic_df = comic[['id','Name', 'Writer', 'Genre', 'Rating', 'Clean_Summary', 'Summary_Keywords',\n",
        "                 'Summary_Keywords_3', 'Summary_Keywords_Synsets']]\n",
        "comic_df.head(1)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>she is young  single and about to achieve her ...</td>\n",
              "      <td>[popular, videogames, single, troublesome, stay]</td>\n",
              "      <td>[popular, videogames, single]</td>\n",
              "      <td>[popular, democratic, pop, videogames, single,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                           Summary_Keywords_Synsets\n",
              "0   0  ...  [popular, democratic, pop, videogames, single,...\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# TfidfVectorize using scikit learn\n",
        "\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vect.fit_transform(comic_df['Summary_literal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08JTng0NxTGD",
        "outputId": "d133b97b-7dee-45a7-bc59-4c169affabbd"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate cosine similarity\n",
        "\n",
        "cosine_sim_tfidf = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# make table of webtoon's name and index\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVTfAXLMzngT",
        "outputId": "a3c19c0c-762f-4379-8146-ab9cedae6560"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# webtoon recommendation fuction by TfidfVectorize\n",
        "\n",
        "def comic_tfidf_rec(title, cosine_sim=cosine_sim_tfidf):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_tfidf_rec(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "OcjfNf6W0rPW",
        "outputId": "44051212-9438-4105-e0d9-3eb15182535c"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>469</td>\n",
              "      <td>My Deepest Secret</td>\n",
              "      <td>Hanza Art</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.68</td>\n",
              "      <td>having a handsome  kind and caring boyfriend l...</td>\n",
              "      <td>[secret, kind]</td>\n",
              "      <td>[secret, kind]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.850389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>Mosquito Wars</td>\n",
              "      <td>JH</td>\n",
              "      <td>Sci-fi</td>\n",
              "      <td>9.62</td>\n",
              "      <td>one hundred years after mosquitoes have evolve...</td>\n",
              "      <td>[humans, humanity, secret, team]</td>\n",
              "      <td>[humans, humanity, secret]</td>\n",
              "      <td>[humans, world, human_race, humanity, humankin...</td>\n",
              "      <td>humans world human_race humanity humankind hum...</td>\n",
              "      <td>0.788014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>CODE HELIX</td>\n",
              "      <td>Na-eum So</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.36</td>\n",
              "      <td>rendra  an intelligent high school student kno...</td>\n",
              "      <td>[classmate, classmates helix, rendra, discover...</td>\n",
              "      <td>[classmate, classmates helix, rendra]</td>\n",
              "      <td>[classmate, schoolmate, schoolfellow, class_fe...</td>\n",
              "      <td>classmate schoolmate schoolfellow class_fellow...</td>\n",
              "      <td>0.586609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Sixth Sense Kiss</td>\n",
              "      <td>Got W / Jocobong</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.71</td>\n",
              "      <td>yesul hong has a secret    when she kisses som...</td>\n",
              "      <td>[secret, work, man, accidentally, vision]</td>\n",
              "      <td>[secret, work, man]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.492236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>Secret Playlist</td>\n",
              "      <td>2F</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.66</td>\n",
              "      <td>hanju is your ordinary university studentâ€¦ e...</td>\n",
              "      <td>[cover, levi, plii, secret]</td>\n",
              "      <td>[cover, levi, plii]</td>\n",
              "      <td>[cover, screen, covert, concealment, blanket, ...</td>\n",
              "      <td>cover screen covert concealment blanket coveri...</td>\n",
              "      <td>0.479251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>The Girl Downstairs</td>\n",
              "      <td>Songah Min</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>when joon moves into his new apartment on his ...</td>\n",
              "      <td>[joon, mysterious]</td>\n",
              "      <td>[joon, mysterious]</td>\n",
              "      <td>[joon, mysterious, cryptic, cryptical, deep, i...</td>\n",
              "      <td>joon mysterious cryptic cryptical deep inscrut...</td>\n",
              "      <td>0.236159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>The Newlywed Diaryof a Witch and a Dragon</td>\n",
              "      <td>New lung / Dimang</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.28</td>\n",
              "      <td>after spending the night with a recent hire of...</td>\n",
              "      <td>[aiden, wendy, secrets, night recent]</td>\n",
              "      <td>[aiden, wendy, secrets]</td>\n",
              "      <td>[aiden, wendy, secrets, secret, arcanum, myste...</td>\n",
              "      <td>aiden wendy secrets secret arcanum mystery eni...</td>\n",
              "      <td>0.211406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>524</td>\n",
              "      <td>Uriah</td>\n",
              "      <td>Toffuo</td>\n",
              "      <td>Horror</td>\n",
              "      <td>9.80</td>\n",
              "      <td>a rainy night  a mysterious island  a boy with...</td>\n",
              "      <td>[story, secrets, journey]</td>\n",
              "      <td>[story, secrets, journey]</td>\n",
              "      <td>[story, narrative, narration, tale, floor, lev...</td>\n",
              "      <td>story narrative narration tale floor level sto...</td>\n",
              "      <td>0.146800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>374</td>\n",
              "      <td>Girls Have a Blog</td>\n",
              "      <td>Sarah Bollinger / Tara Kurtzhals</td>\n",
              "      <td>Slice of life</td>\n",
              "      <td>9.17</td>\n",
              "      <td>creating comics  playing videos games  eating ...</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>videos games</td>\n",
              "      <td>0.137256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>476</td>\n",
              "      <td>Flawless</td>\n",
              "      <td>Shinshinhye</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.68</td>\n",
              "      <td>sarah is a tough girl who prides herself for b...</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, enigma, secret, closed_book, mystery...</td>\n",
              "      <td>mystery enigma secret closed_book mystery_stor...</td>\n",
              "      <td>0.133837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "469  469  ...  0.850389\n",
              "270  270  ...  0.788014\n",
              "65    65  ...  0.586609\n",
              "16    16  ...  0.492236\n",
              "28    28  ...  0.479251\n",
              "49    49  ...  0.236159\n",
              "196  196  ...  0.211406\n",
              "524  524  ...  0.146800\n",
              "374  374  ...  0.137256\n",
              "476  476  ...  0.133837\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorize using scikit learn\n",
        "\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
        "count_matrix = count_vect.fit_transform(comic_df['Summary_literal'])\n",
        "print(count_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW8Y2divgNco",
        "outputId": "86461d8a-dfb3-46b6-8bdb-2699218baca2"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 14629)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_sim_count = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9C3jVWQgQIO",
        "outputId": "c89cf4f1-cc1a-4df7-87a2-c2e23d509825"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# webtoon recommendation fuction by CountVectorize\n",
        "\n",
        "def comic_count_REC(title, cosine_sim=cosine_sim_count):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_count_REC(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "v_Vv6COshG8J",
        "outputId": "a5ad6e6e-e03d-424f-fef1-e6ced8fd8bbc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>469</td>\n",
              "      <td>My Deepest Secret</td>\n",
              "      <td>Hanza Art</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.68</td>\n",
              "      <td>having a handsome  kind and caring boyfriend l...</td>\n",
              "      <td>[secret, kind]</td>\n",
              "      <td>[secret, kind]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.863338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>Mosquito Wars</td>\n",
              "      <td>JH</td>\n",
              "      <td>Sci-fi</td>\n",
              "      <td>9.62</td>\n",
              "      <td>one hundred years after mosquitoes have evolve...</td>\n",
              "      <td>[humans, humanity, secret, team]</td>\n",
              "      <td>[humans, humanity, secret]</td>\n",
              "      <td>[humans, world, human_race, humanity, humankin...</td>\n",
              "      <td>humans world human_race humanity humankind hum...</td>\n",
              "      <td>0.751439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>CODE HELIX</td>\n",
              "      <td>Na-eum So</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.36</td>\n",
              "      <td>rendra  an intelligent high school student kno...</td>\n",
              "      <td>[classmate, classmates helix, rendra, discover...</td>\n",
              "      <td>[classmate, classmates helix, rendra]</td>\n",
              "      <td>[classmate, schoolmate, schoolfellow, class_fe...</td>\n",
              "      <td>classmate schoolmate schoolfellow class_fellow...</td>\n",
              "      <td>0.600545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>Secret Playlist</td>\n",
              "      <td>2F</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.66</td>\n",
              "      <td>hanju is your ordinary university studentâ€¦ e...</td>\n",
              "      <td>[cover, levi, plii, secret]</td>\n",
              "      <td>[cover, levi, plii]</td>\n",
              "      <td>[cover, screen, covert, concealment, blanket, ...</td>\n",
              "      <td>cover screen covert concealment blanket coveri...</td>\n",
              "      <td>0.543852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Sixth Sense Kiss</td>\n",
              "      <td>Got W / Jocobong</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.71</td>\n",
              "      <td>yesul hong has a secret    when she kisses som...</td>\n",
              "      <td>[secret, work, man, accidentally, vision]</td>\n",
              "      <td>[secret, work, man]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.502939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>The Newlywed Diaryof a Witch and a Dragon</td>\n",
              "      <td>New lung / Dimang</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.28</td>\n",
              "      <td>after spending the night with a recent hire of...</td>\n",
              "      <td>[aiden, wendy, secrets, night recent]</td>\n",
              "      <td>[aiden, wendy, secrets]</td>\n",
              "      <td>[aiden, wendy, secrets, secret, arcanum, myste...</td>\n",
              "      <td>aiden wendy secrets secret arcanum mystery eni...</td>\n",
              "      <td>0.245040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>The Girl Downstairs</td>\n",
              "      <td>Songah Min</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>when joon moves into his new apartment on his ...</td>\n",
              "      <td>[joon, mysterious]</td>\n",
              "      <td>[joon, mysterious]</td>\n",
              "      <td>[joon, mysterious, cryptic, cryptical, deep, i...</td>\n",
              "      <td>joon mysterious cryptic cryptical deep inscrut...</td>\n",
              "      <td>0.197969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>524</td>\n",
              "      <td>Uriah</td>\n",
              "      <td>Toffuo</td>\n",
              "      <td>Horror</td>\n",
              "      <td>9.80</td>\n",
              "      <td>a rainy night  a mysterious island  a boy with...</td>\n",
              "      <td>[story, secrets, journey]</td>\n",
              "      <td>[story, secrets, journey]</td>\n",
              "      <td>[story, narrative, narration, tale, floor, lev...</td>\n",
              "      <td>story narrative narration tale floor level sto...</td>\n",
              "      <td>0.152586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>476</td>\n",
              "      <td>Flawless</td>\n",
              "      <td>Shinshinhye</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.68</td>\n",
              "      <td>sarah is a tough girl who prides herself for b...</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, enigma, secret, closed_book, mystery...</td>\n",
              "      <td>mystery enigma secret closed_book mystery_stor...</td>\n",
              "      <td>0.118678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>222</td>\n",
              "      <td>The Lazy Lord Masters the Sword</td>\n",
              "      <td>Dodomoon / doip</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.65</td>\n",
              "      <td>after witnessing the shocking death of his mot...</td>\n",
              "      <td>[whispers intention, complete, mysterious]</td>\n",
              "      <td>[whispers intention, complete, mysterious]</td>\n",
              "      <td>[whispers intention, complete, finish, dispatc...</td>\n",
              "      <td>whispers intention complete finish dispatch di...</td>\n",
              "      <td>0.105492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "469  469  ...  0.863338\n",
              "270  270  ...  0.751439\n",
              "65    65  ...  0.600545\n",
              "28    28  ...  0.543852\n",
              "16    16  ...  0.502939\n",
              "196  196  ...  0.245040\n",
              "49    49  ...  0.197969\n",
              "524  524  ...  0.152586\n",
              "476  476  ...  0.118678\n",
              "222  222  ...  0.105492\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    }
  ]
}