{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "코싸인유사도적용.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungyeon38/Webtoon_recommendation_system/blob/master/CountVectorize%20%2B%20TFIDFVectorize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3HzhmAim89R",
        "outputId": "9281bcb4-e309-49be-997c-40fe2bf8a5b2"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AEKymwhWxV",
        "outputId": "156f0bcd-ac10-4d5a-b0e1-489639a58ce1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "string.punctuation\n",
        "from math import log\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from gensim.summarization import keywords\n",
        "from textblob import TextBlob\n",
        "\n",
        "!pip install gensim\n",
        "!pip install konlpy"
      ],
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBTfyqehdID"
      },
      "source": [
        "comic = pd.read_csv('/content/drive/MyDrive/webtoon/Webtoon Dataset.csv')"
      ],
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_comic = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjOwaO2zv0sW",
        "outputId": "d6b23033-f040-40b7-d8e2-fbf5c228e919"
      },
      "execution_count": 452,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Beauty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " selected_comic = comic.loc[(comic.Name == input_comic)]\n",
        "\n",
        " print(selected_comic['Name'])"
      ],
      "metadata": {
        "id": "7UunDt7dvtYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e150f0-cb13-4e0d-cb12-aadd928c8c68"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    True Beauty\n",
            "Name: Name, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsmb3sHGhdev"
      },
      "source": [
        "# 축약형 \n",
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"she's\": \"she is\"}\n",
        "\n",
        "def regularize_contractions(text):\n",
        "\n",
        "    contractionfree_list = []\n",
        "    \n",
        "    for word in text.split(\" \"):\n",
        "      if word in contractions.keys():\n",
        "        contractionfree_list.append(contractions[word])\n",
        "      else :\n",
        "        contractionfree_list.append(word)\n",
        "      \n",
        "    return \" \".join(contractionfree_list)\n"
      ],
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpeOq8H5WV_"
      },
      "source": [
        "#defining the function to remove punctuation\n",
        "# 글자가 puctuation에 해당하면 \" \"를, 해당하지 않으면 글자 그대로\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree_list = []\n",
        "\n",
        "    for word in text:\n",
        "      if word in string.punctuation:\n",
        "        punctuationfree_list.append(\" \")\n",
        "      else :\n",
        "        punctuationfree_list.append(word)\n",
        "    return \"\".join(punctuationfree_list)\n",
        "\n",
        "\n",
        "# def remove_punctuation(text):\n",
        "#     punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
        "#     return punctuationfree"
      ],
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_YijrK_flsD"
      },
      "source": [
        "# #defining function for tokenization\n",
        "# 숫자 포함 토큰화\n",
        "# def tokenization(text):\n",
        "#     tokens = re.split('\\W+', text)\n",
        "\n",
        "#     return tokens\n",
        "\n",
        "# 영어만 단어단위로 토큰화\n",
        "p = re.compile('[a-z]+')\n",
        "\n",
        "def tokenization(text):\n",
        "    # print(text)\n",
        "    result = p.findall(text)\n",
        "    # print(result)\n",
        "    return result"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t9lmVILpJ5J"
      },
      "source": [
        "#stop words present in the library\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "# print(stopwords[:20]) \n",
        "\n",
        "#defining the function to remove stopwords from tokenized text\n",
        "# stopwords 제거 \n",
        "def remove_stopwords(text):\n",
        "    for word in text:\n",
        "      output= [word for word in text if word not in stopwords]\n",
        "    return output"
      ],
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsyAbTHb5Wl",
        "outputId": "f2f97bd0-44ae-4e81-878a-502a9c21b23a"
      },
      "source": [
        "#setting lower case\n",
        "comic['Lower_Summary'] = comic['Summary'].apply(lambda x: x.lower())\n",
        "comic['Lower_Summary'].head(3)"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she's young, single and about to achieve her d...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Lower_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ksxt3pIkA7O",
        "outputId": "e0474114-8910-478a-c12b-21cb1136cf3c"
      },
      "source": [
        "comic['No_Contraction_Summary'] = comic['Lower_Summary'].apply(lambda x:regularize_contractions(x))\n",
        "comic['No_Contraction_Summary'].head(3)"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young, single and about to achieve her ...\n",
              "1    after binge-watching beauty videos online, a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: No_Contraction_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6dBD6jokDNl",
        "outputId": "caf5da0e-69cb-41e6-8c07-64cc03a8add6"
      },
      "source": [
        "comic['Clean_Summary'] = comic['No_Contraction_Summary'].apply(lambda x:remove_punctuation(x))\n",
        "comic['Clean_Summary'].head(3)"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    she is young  single and about to achieve her ...\n",
              "1    after binge watching beauty videos online  a s...\n",
              "2    after making a grisly discovery in the country...\n",
              "Name: Clean_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 460
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu8IBMAomStz",
        "outputId": "6c7adc0c-e937-4078-a62d-f7a6260c4c59"
      },
      "source": [
        "#applying function to the column\n",
        "comic['Tokenied_Summary'] = comic['Clean_Summary'].apply(lambda x: tokenization(x))\n",
        "\n",
        "comic['Tokenied_Summary'].head(3)"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [she, is, young, single, and, about, to, achie...\n",
              "1    [after, binge, watching, beauty, videos, onlin...\n",
              "2    [after, making, a, grisly, discovery, in, the,...\n",
              "Name: Tokenied_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CpN1ehSdabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece04d96-4338-4033-df59-58b1dc0aeb44"
      },
      "source": [
        "#applying the function\n",
        "comic['No_Stopwords_Summary'] = comic['Tokenied_Summary'].apply(lambda x:remove_stopwords(x))\n",
        "\n",
        "comic['No_Stopwords_Summary'].head(3)"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, creating, incr...\n",
              "1    [binge, watching, beauty, videos, online, shy,...\n",
              "2    [making, grisly, discovery, countryside, small...\n",
              "Name: No_Stopwords_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_no_verb(text):\n",
        "  part_of_speech_text = pos_tag(text)\n",
        "  result = []\n",
        "  for word in part_of_speech_text:\n",
        "    if word[1] != \"VB\" and word[1] != \"VBD\" and word[1] != \"VBG\" and word[1] != \"VBN\" and word[1] != \"VBP\" and word[1] != \"VBZ\":\n",
        "        result.append(word[0])\n",
        "  return result; \n",
        "\n",
        "comic['No_Verb_Summary'] = comic['No_Stopwords_Summary'].apply(lambda x:extract_no_verb(x))\n",
        "\n",
        "comic['No_Verb_Summary'].head(3)"
      ],
      "metadata": {
        "id": "4LON9acgf0xx",
        "outputId": "65494165-18fa-467b-c354-398aa80deaec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [young, single, achieve, dream, incredible, vi...\n",
              "1    [binge, beauty, videos, online, shy, comic, bo...\n",
              "2    [grisly, discovery, countryside, small, town, ...\n",
              "Name: No_Verb_Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqFR0C4gddRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e04e5c-def7-4910-c9d9-83f794936eb8"
      },
      "source": [
        "# df1 = comic['No_Stopwords_Summary']\n",
        "# doc_words_list = df1.values.tolist()\n",
        "\n",
        "# print(doc_words_list)\n",
        "\n",
        "\n",
        "def wordlist_to_string(words_list) :\n",
        "  doc = []\n",
        "  for doc_word in words_list :\n",
        "    doc.append(doc_word)\n",
        "  return \" \".join(doc)\n",
        "\n",
        "\n",
        "#comic['Summary_final'] = comic['Stemmed_Summary'].apply(lambda x:wordlist_to_string(x))\n",
        "comic['Summary_final'] = comic['No_Verb_Summary'].apply(lambda x:wordlist_to_string(x))\n",
        "\n",
        "comic['Summary_final'].head(3)"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    young single achieve dream incredible videogam...\n",
              "1    binge beauty videos online shy comic book fan ...\n",
              "2    grisly discovery countryside small town book e...\n",
              "Name: Summary_final, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW6gJoIYxfhl"
      },
      "source": [
        "def extract_keywords(doc):\n",
        "  keyword_list = []\n",
        "  keyword_string = keywords(doc)\n",
        "  keyword_list = keyword_string.split('\\n')\n",
        "\n",
        "  return keyword_list;\n",
        "\n",
        "\n",
        "comic['Summary_Keywords'] = comic['Summary_final'].apply(lambda x:extract_keywords(x))"
      ],
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_3(keyword_list):\n",
        "  keyword_list_3 = keyword_list[0:3]\n",
        "\n",
        "  return keyword_list_3\n",
        "\n",
        "comic['Summary_Keywords_3'] = comic['Summary_Keywords'].apply(lambda x:keyword_3(x))\n",
        "\n",
        "comic.head(10)"
      ],
      "metadata": {
        "id": "xg6fXrcZtCV3",
        "outputId": "9805a952-5014-4335-fd3b-09aa811b5533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Subscribers</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Update</th>\n",
              "      <th>Reading Link</th>\n",
              "      <th>Lower_Summary</th>\n",
              "      <th>No_Contraction_Summary</th>\n",
              "      <th>Clean_Summary</th>\n",
              "      <th>Tokenied_Summary</th>\n",
              "      <th>No_Stopwords_Summary</th>\n",
              "      <th>No_Verb_Summary</th>\n",
              "      <th>Summary_final</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>30.6M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>4.2M</td>\n",
              "      <td>She's young, single and about to achieve her d...</td>\n",
              "      <td>UP EVERY TUESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/letsplay/l...</td>\n",
              "      <td>she's young, single and about to achieve her d...</td>\n",
              "      <td>she is young, single and about to achieve her ...</td>\n",
              "      <td>she is young  single and about to achieve her ...</td>\n",
              "      <td>[she, is, young, single, and, about, to, achie...</td>\n",
              "      <td>[young, single, achieve, dream, creating, incr...</td>\n",
              "      <td>[young, single, achieve, dream, incredible, vi...</td>\n",
              "      <td>young single achieve dream incredible videogam...</td>\n",
              "      <td>[popular, single, videogames, stay, troublesome]</td>\n",
              "      <td>[popular, single, videogames]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True Beauty</td>\n",
              "      <td>Yaongyi</td>\n",
              "      <td>39.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.60</td>\n",
              "      <td>6.4M</td>\n",
              "      <td>After binge-watching beauty videos online, a s...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/truebeauty...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge-watching beauty videos online, a s...</td>\n",
              "      <td>after binge watching beauty videos online  a s...</td>\n",
              "      <td>[after, binge, watching, beauty, videos, onlin...</td>\n",
              "      <td>[binge, watching, beauty, videos, online, shy,...</td>\n",
              "      <td>[binge, beauty, videos, online, shy, comic, bo...</td>\n",
              "      <td>binge beauty videos online shy comic book fan ...</td>\n",
              "      <td>[secret, beauty videos, status short]</td>\n",
              "      <td>[secret, beauty videos, status short]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Midnight Poppy Land</td>\n",
              "      <td>Lilydusk</td>\n",
              "      <td>10.4M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.81</td>\n",
              "      <td>2.1M</td>\n",
              "      <td>After making a grisly discovery in the country...</td>\n",
              "      <td>UP EVERY SATURDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/midnight-p...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>after making a grisly discovery in the country...</td>\n",
              "      <td>[after, making, a, grisly, discovery, in, the,...</td>\n",
              "      <td>[making, grisly, discovery, countryside, small...</td>\n",
              "      <td>[grisly, discovery, countryside, small, town, ...</td>\n",
              "      <td>grisly discovery countryside small town book e...</td>\n",
              "      <td>[deeper dangerous underworld]</td>\n",
              "      <td>[deeper dangerous underworld]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Age Matters</td>\n",
              "      <td>Enjelicious</td>\n",
              "      <td>25.9M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.79</td>\n",
              "      <td>3.5M</td>\n",
              "      <td>She's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/age-matter...</td>\n",
              "      <td>she's a hopeless romantic who's turning 30's  ...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30's...</td>\n",
              "      <td>she is a hopeless romantic who is turning 30 s...</td>\n",
              "      <td>[she, is, a, hopeless, romantic, who, is, turn...</td>\n",
              "      <td>[hopeless, romantic, turning, super, happy, re...</td>\n",
              "      <td>[hopeless, romantic, super, happy, reclusive, ...</td>\n",
              "      <td>hopeless romantic super happy reclusive billio...</td>\n",
              "      <td>[happy, way]</td>\n",
              "      <td>[happy, way]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Unholy Blood</td>\n",
              "      <td>Lina Im / Jeonghyeon Kim</td>\n",
              "      <td>9.9M</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.85</td>\n",
              "      <td>1.5M</td>\n",
              "      <td>When vampires destroy her chance to have the n...</td>\n",
              "      <td>UP EVERY THURSDAY</td>\n",
              "      <td>https://www.webtoons.com/en/supernatural/unhol...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>when vampires destroy her chance to have the n...</td>\n",
              "      <td>[when, vampires, destroy, her, chance, to, hav...</td>\n",
              "      <td>[vampires, destroy, chance, normal, life, alwa...</td>\n",
              "      <td>[vampires, chance, normal, life, always, hayan...</td>\n",
              "      <td>vampires chance normal life always hayan draw ...</td>\n",
              "      <td>[hayan, chance normal, ones]</td>\n",
              "      <td>[hayan, chance normal, ones]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LUMINE</td>\n",
              "      <td>Emma Krogell</td>\n",
              "      <td>18.9M</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.82</td>\n",
              "      <td>3M</td>\n",
              "      <td>A runaway werewolf, Lumine, meets a witch boy ...</td>\n",
              "      <td>UP EVERY SUNDAY</td>\n",
              "      <td>https://www.webtoons.com/en/fantasy/lumine/lis...</td>\n",
              "      <td>a runaway werewolf, lumine, meets a witch boy ...</td>\n",
              "      <td>a runaway werewolf, lumine, meets a witch boy ...</td>\n",
              "      <td>a runaway werewolf  lumine  meets a witch boy ...</td>\n",
              "      <td>[a, runaway, werewolf, lumine, meets, a, witch...</td>\n",
              "      <td>[runaway, werewolf, lumine, meets, witch, boy,...</td>\n",
              "      <td>[runaway, werewolf, lumine, meets, boy, kody, ...</td>\n",
              "      <td>runaway werewolf lumine meets boy kody work bo...</td>\n",
              "      <td>[kody, lumine, event]</td>\n",
              "      <td>[kody, lumine, event]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Jackson's Diary</td>\n",
              "      <td>Paola Batalla</td>\n",
              "      <td>2.9M</td>\n",
              "      <td>Supernatural</td>\n",
              "      <td>9.66</td>\n",
              "      <td>649K</td>\n",
              "      <td>The year is 1989, and Jackson is starting his ...</td>\n",
              "      <td>UP EVERY SUNDAY</td>\n",
              "      <td>https://www.webtoons.com/en/supernatural/jacks...</td>\n",
              "      <td>the year is 1989, and jackson is starting his ...</td>\n",
              "      <td>the year is 1989, and jackson is starting his ...</td>\n",
              "      <td>the year is 1989  and jackson is starting his ...</td>\n",
              "      <td>[the, year, is, and, jackson, is, starting, hi...</td>\n",
              "      <td>[year, jackson, starting, senior, year, brand,...</td>\n",
              "      <td>[year, jackson, senior, year, brand, new, scho...</td>\n",
              "      <td>year jackson senior year brand new school even...</td>\n",
              "      <td>[new, year, work, ominous]</td>\n",
              "      <td>[new, year, work]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Teenage Mercenary</td>\n",
              "      <td>YC / Rakyeon</td>\n",
              "      <td>9,29,796</td>\n",
              "      <td>Action</td>\n",
              "      <td>9.87</td>\n",
              "      <td>537.6K</td>\n",
              "      <td>At the age of eight, Ijin Yu lost his parents ...</td>\n",
              "      <td>UP EVERY WEDNESDAY</td>\n",
              "      <td>https://www.webtoons.com/en/action/teenage-mer...</td>\n",
              "      <td>at the age of eight, ijin yu lost his parents ...</td>\n",
              "      <td>at the age of eight, ijin yu lost his parents ...</td>\n",
              "      <td>at the age of eight  ijin yu lost his parents ...</td>\n",
              "      <td>[at, the, age, of, eight, ijin, yu, lost, his,...</td>\n",
              "      <td>[age, eight, ijin, yu, lost, parents, plane, c...</td>\n",
              "      <td>[age, eight, ijin, yu, parents, plane, crash, ...</td>\n",
              "      <td>age eight ijin yu parents plane crash stranded...</td>\n",
              "      <td>[survival, survive, ijin, school, years, year,...</td>\n",
              "      <td>[survival, survive, ijin]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Nice To Meet You</td>\n",
              "      <td>Wishroomness</td>\n",
              "      <td>5.8M</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.82</td>\n",
              "      <td>1.1M</td>\n",
              "      <td>A ditsy university student Mew finds a lost st...</td>\n",
              "      <td>UP EVERY MONDAY</td>\n",
              "      <td>https://www.webtoons.com/en/romance/nice-to-me...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>a ditsy university student mew finds a lost st...</td>\n",
              "      <td>[a, ditsy, university, student, mew, finds, a,...</td>\n",
              "      <td>[ditsy, university, student, mew, finds, lost,...</td>\n",
              "      <td>[ditsy, university, student, mew, student, car...</td>\n",
              "      <td>ditsy university student mew student card inst...</td>\n",
              "      <td>[card, mew, little, life]</td>\n",
              "      <td>[card, mew, little]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>I Love Yoo</td>\n",
              "      <td>Quimchee</td>\n",
              "      <td>29M</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.78</td>\n",
              "      <td>4.3M</td>\n",
              "      <td>Dogged by pain and misfortune from the very be...</td>\n",
              "      <td>UP EVERY FRIDAY</td>\n",
              "      <td>https://www.webtoons.com/en/drama/i-love-yoo/l...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>dogged by pain and misfortune from the very be...</td>\n",
              "      <td>[dogged, by, pain, and, misfortune, from, the,...</td>\n",
              "      <td>[dogged, pain, misfortune, beginning, shin, ae...</td>\n",
              "      <td>[pain, misfortune, shin, ae, decides, nothing,...</td>\n",
              "      <td>pain misfortune shin ae decides nothing people...</td>\n",
              "      <td>[misfortune, strangers]</td>\n",
              "      <td>[misfortune, strangers]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                     Summary_Keywords_3\n",
              "0   0  ...          [popular, single, videogames]\n",
              "1   1  ...  [secret, beauty videos, status short]\n",
              "2   2  ...          [deeper dangerous underworld]\n",
              "3   3  ...                           [happy, way]\n",
              "4   4  ...           [hayan, chance normal, ones]\n",
              "5   5  ...                  [kody, lumine, event]\n",
              "6   6  ...                      [new, year, work]\n",
              "7   7  ...              [survival, survive, ijin]\n",
              "8   8  ...                    [card, mew, little]\n",
              "9   9  ...                [misfortune, strangers]\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence = []\n",
        "#for user_sentence in comic['No_Verb_Summary'].values:\n",
        "#  sentence.append(list(map(str, user_sentence)))"
      ],
      "metadata": {
        "id": "rm4xKpSl-4oX"
      },
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from gensim import Word2Vec\n",
        "\n",
        "#embedding_model = Word2Vec(sentence, size = 20, window = 5, min_count = 2, workers = 4, iter = 300, sg = 1)\n"
      ],
      "metadata": {
        "id": "UbJl-2v-_x0D"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding_model.wv.most_similar(positive = comic[''], topn = 10)"
      ],
      "metadata": {
        "id": "13HL_psiBfM9"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#synsets(검색) -> 리스트\n",
        "\n",
        "#synset(신셋색인)  .definition() .examples()  .lemmas()  .hyponyms()\n",
        "# wordnet.synset('young.a.01').definition()\n",
        "# wordnet.synset('beauty.n.01').hypernym_paths()\n",
        "# word_beautiful = wordnet.synset('beautiful.a.01')\n",
        "# word_pretty = wordnet.synset('pretty.a.01')\n",
        "# print(word_pretty.wup_similarity(word_beautiful))\n",
        "\n",
        "# dog = wordnet.synset('dog.n.01')\n",
        "# cat = wordnet.synset('cat.n.01')\n",
        "\n",
        "# print(dog.wup_similarity(cat))\n",
        "\n",
        "\n",
        "!pip install textblob\n",
        "\n",
        "\n",
        "# pos_tag([\"beauty\"])\n",
        "\n",
        "# wordnet.synset('car.n.01').definition() wordnet.synset('car.n.01').examples() wordnet.synset('car.n.01').lemmas()\n",
        "\n",
        "# comic['Summary_Keywords_3'] = comic['Summary_Keywords'].apply(lambda x:keyword_3(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuxt5l5o_BB",
        "outputId": "34aea213-7bee-4c8e-debf-ebfcb3a8fda5"
      },
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# word = Word(\"beauty\")\n",
        "# print(word.synsets)\n",
        "\n",
        "def keyword_synsets(keywords):\n",
        "  keyword_synsets = []\n",
        "  for i in range(len(keywords)):\n",
        "    keyword_synsets.append(keywords[i])\n",
        "    word = Word(keywords[i])\n",
        "    for synset in word.synsets:\n",
        "      for lemma in synset.lemmas():\n",
        "        if lemma.name() not in keyword_synsets:\n",
        "          keyword_synsets.append(lemma.name())\n",
        "\n",
        "  return keyword_synsets\n",
        "\n",
        "\n",
        "comic['Summary_Keywords_Synsets'] = comic['Summary_Keywords'].apply(lambda x:keyword_synsets(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H6EGbjORSNJ",
        "outputId": "ee8a1088-ea95-4660-d144-9de5badd1a44"
      },
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comic['Summary_Keywords'].head(1)\n",
        "comic['Summary_Keywords_Synsets'].head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yf4ESd4Zck6",
        "outputId": "819778c4-9289-4c48-d943-93b5c5372340"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [popular, democratic, pop, single, bingle, one...\n",
              "Name: Summary_Keywords_Synsets, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "jYpGYoX32BpS",
        "outputId": "71bc2629-9416-4571-a350-718afe6a8441"
      },
      "source": [
        "comic_df = comic[['id','Name', 'Writer', 'Genre', 'Rating', 'Summary_Keywords',\n",
        "                 'Summary_Keywords_3', 'Summary_Keywords_Synsets']]\n",
        "comic_df.head(1)"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Let's Play</td>\n",
              "      <td>Leeanne M. Krecic (Mongie)</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[popular, single, videogames, stay, troublesome]</td>\n",
              "      <td>[popular, single, videogames]</td>\n",
              "      <td>[popular, democratic, pop, single, bingle, one...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                           Summary_Keywords_Synsets\n",
              "0   0  ...  [popular, democratic, pop, single, bingle, one...\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(comic_df['Summary_literal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08JTng0NxTGD",
        "outputId": "bc8d6412-22ba-4e13-d243-27b0b1597893"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVTfAXLMzngT",
        "outputId": "4f08f88d-105e-4eee-9bf8-8cad92bdf39e"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comic_REC(title, cosine_sim=cosine_sim):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_REC(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "OcjfNf6W0rPW",
        "outputId": "125bc83b-28be-444e-9ecb-03f10c7bee5a"
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>Mosquito Wars</td>\n",
              "      <td>JH</td>\n",
              "      <td>Sci-fi</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[humans, humanity, team, secret]</td>\n",
              "      <td>[humans, humanity, team]</td>\n",
              "      <td>[humans, world, human_race, humanity, humankin...</td>\n",
              "      <td>humans world human_race humanity humankind hum...</td>\n",
              "      <td>0.786818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>469</td>\n",
              "      <td>My Deepest Secret</td>\n",
              "      <td>Hanza Art</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.68</td>\n",
              "      <td>[secret, world]</td>\n",
              "      <td>[secret, world]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.755553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>CODE HELIX</td>\n",
              "      <td>Na-eum So</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.36</td>\n",
              "      <td>[classmate, classmates helix, rendra, discover...</td>\n",
              "      <td>[classmate, classmates helix, rendra]</td>\n",
              "      <td>[classmate, schoolmate, schoolfellow, class_fe...</td>\n",
              "      <td>classmate schoolmate schoolfellow class_fellow...</td>\n",
              "      <td>0.586392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Sixth Sense Kiss</td>\n",
              "      <td>Got W / Jocobong</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.71</td>\n",
              "      <td>[secret, work, man, accidentally, vision]</td>\n",
              "      <td>[secret, work, man]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.490265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>Secret Playlist</td>\n",
              "      <td>2F</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.66</td>\n",
              "      <td>[cover, levi, plii, secret]</td>\n",
              "      <td>[cover, levi, plii]</td>\n",
              "      <td>[cover, screen, covert, concealment, blanket, ...</td>\n",
              "      <td>cover screen covert concealment blanket coveri...</td>\n",
              "      <td>0.479800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>The Newlywed Diaryof a Witch and a Dragon</td>\n",
              "      <td>New lung / Dimang</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.28</td>\n",
              "      <td>[aiden, wendy, secrets, night recent]</td>\n",
              "      <td>[aiden, wendy, secrets]</td>\n",
              "      <td>[aiden, wendy, secrets, secret, arcanum, myste...</td>\n",
              "      <td>aiden wendy secrets secret arcanum mystery eni...</td>\n",
              "      <td>0.213236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>537</td>\n",
              "      <td>PIGPEN</td>\n",
              "      <td>Carnby Kim / Beom Sick Cheon</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.74</td>\n",
              "      <td>[questions family, mystery]</td>\n",
              "      <td>[questions family, mystery]</td>\n",
              "      <td>[questions family, mystery, enigma, secret, cl...</td>\n",
              "      <td>questions family mystery enigma secret closed_...</td>\n",
              "      <td>0.192314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>374</td>\n",
              "      <td>Girls Have a Blog</td>\n",
              "      <td>Sarah Bollinger / Tara Kurtzhals</td>\n",
              "      <td>Slice of life</td>\n",
              "      <td>9.17</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>[videos games]</td>\n",
              "      <td>videos games</td>\n",
              "      <td>0.137069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>476</td>\n",
              "      <td>Flawless</td>\n",
              "      <td>Shinshinhye</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.68</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, enigma, secret, closed_book, mystery...</td>\n",
              "      <td>mystery enigma secret closed_book mystery_stor...</td>\n",
              "      <td>0.136302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>132</td>\n",
              "      <td>God of Bath</td>\n",
              "      <td>Ilkwon Ha</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>9.51</td>\n",
              "      <td>[scrubber, old, loan, mysterious]</td>\n",
              "      <td>[scrubber, old, loan]</td>\n",
              "      <td>[scrubber, scrub_brush, scrubbing_brush, old, ...</td>\n",
              "      <td>scrubber scrub_brush scrubbing_brush old older...</td>\n",
              "      <td>0.127035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "270  270  ...  0.786818\n",
              "469  469  ...  0.755553\n",
              "65    65  ...  0.586392\n",
              "16    16  ...  0.490265\n",
              "28    28  ...  0.479800\n",
              "196  196  ...  0.213236\n",
              "537  537  ...  0.192314\n",
              "374  374  ...  0.137069\n",
              "476  476  ...  0.136302\n",
              "132  132  ...  0.127035\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "comic_df['Summary_literal'] = comic_df['Summary_Keywords_Synsets'].apply(lambda x : (' ').join(x))\n",
        "count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
        "Summary_mat = count_vect.fit_transform(comic_df['Summary_literal'])\n",
        "print(Summary_mat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW8Y2divgNco",
        "outputId": "5c1d449f-716b-46f0-d631-a1b623938722"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 14727)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_sim = cosine_similarity(Summary_mat, Summary_mat)\n",
        "\n",
        "indices = pd.Series(comic_df.index, index=comic_df['Name']).drop_duplicates()\n",
        "print(indices.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9C3jVWQgQIO",
        "outputId": "0552beaf-361c-4a2f-a806-50588c1d18a9"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Let's Play             0\n",
            "True Beauty            1\n",
            "Midnight Poppy Land    2\n",
            "Age Matters            3\n",
            "Unholy Blood           4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comic_REC(title, cosine_sim=cosine_sim):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    comic_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    result_df = comic_df.iloc[comic_indices].copy()\n",
        "    result_df['sim_score'] = [i[1] for i in sim_scores]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "comic_REC(input_comic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "v_Vv6COshG8J",
        "outputId": "36d04503-129d-40fc-f16f-bfa6f3136818"
      },
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Summary_Keywords</th>\n",
              "      <th>Summary_Keywords_3</th>\n",
              "      <th>Summary_Keywords_Synsets</th>\n",
              "      <th>Summary_literal</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>Mosquito Wars</td>\n",
              "      <td>JH</td>\n",
              "      <td>Sci-fi</td>\n",
              "      <td>9.62</td>\n",
              "      <td>[humans, humanity, team, secret]</td>\n",
              "      <td>[humans, humanity, team]</td>\n",
              "      <td>[humans, world, human_race, humanity, humankin...</td>\n",
              "      <td>humans world human_race humanity humankind hum...</td>\n",
              "      <td>0.751439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>469</td>\n",
              "      <td>My Deepest Secret</td>\n",
              "      <td>Hanza Art</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.68</td>\n",
              "      <td>[secret, world]</td>\n",
              "      <td>[secret, world]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.679702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>CODE HELIX</td>\n",
              "      <td>Na-eum So</td>\n",
              "      <td>Drama</td>\n",
              "      <td>9.36</td>\n",
              "      <td>[classmate, classmates helix, rendra, discover...</td>\n",
              "      <td>[classmate, classmates helix, rendra]</td>\n",
              "      <td>[classmate, schoolmate, schoolfellow, class_fe...</td>\n",
              "      <td>classmate schoolmate schoolfellow class_fellow...</td>\n",
              "      <td>0.600545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>Secret Playlist</td>\n",
              "      <td>2F</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.66</td>\n",
              "      <td>[cover, levi, plii, secret]</td>\n",
              "      <td>[cover, levi, plii]</td>\n",
              "      <td>[cover, screen, covert, concealment, blanket, ...</td>\n",
              "      <td>cover screen covert concealment blanket coveri...</td>\n",
              "      <td>0.543852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Sixth Sense Kiss</td>\n",
              "      <td>Got W / Jocobong</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.71</td>\n",
              "      <td>[secret, work, man, accidentally, vision]</td>\n",
              "      <td>[secret, work, man]</td>\n",
              "      <td>[secret, arcanum, mystery, enigma, closed_book...</td>\n",
              "      <td>secret arcanum mystery enigma closed_book clan...</td>\n",
              "      <td>0.502939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>The Newlywed Diaryof a Witch and a Dragon</td>\n",
              "      <td>New lung / Dimang</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.28</td>\n",
              "      <td>[aiden, wendy, secrets, night recent]</td>\n",
              "      <td>[aiden, wendy, secrets]</td>\n",
              "      <td>[aiden, wendy, secrets, secret, arcanum, myste...</td>\n",
              "      <td>aiden wendy secrets secret arcanum mystery eni...</td>\n",
              "      <td>0.245040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>537</td>\n",
              "      <td>PIGPEN</td>\n",
              "      <td>Carnby Kim / Beom Sick Cheon</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>9.74</td>\n",
              "      <td>[questions family, mystery]</td>\n",
              "      <td>[questions family, mystery]</td>\n",
              "      <td>[questions family, mystery, enigma, secret, cl...</td>\n",
              "      <td>questions family mystery enigma secret closed_...</td>\n",
              "      <td>0.153213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>476</td>\n",
              "      <td>Flawless</td>\n",
              "      <td>Shinshinhye</td>\n",
              "      <td>Romance</td>\n",
              "      <td>9.68</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, prides, street]</td>\n",
              "      <td>[mystery, enigma, secret, closed_book, mystery...</td>\n",
              "      <td>mystery enigma secret closed_book mystery_stor...</td>\n",
              "      <td>0.118678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>132</td>\n",
              "      <td>God of Bath</td>\n",
              "      <td>Ilkwon Ha</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>9.51</td>\n",
              "      <td>[scrubber, old, loan, mysterious]</td>\n",
              "      <td>[scrubber, old, loan]</td>\n",
              "      <td>[scrubber, scrub_brush, scrubbing_brush, old, ...</td>\n",
              "      <td>scrubber scrub_brush scrubbing_brush old older...</td>\n",
              "      <td>0.106819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>222</td>\n",
              "      <td>The Lazy Lord Masters the Sword</td>\n",
              "      <td>Dodomoon / doip</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>9.65</td>\n",
              "      <td>[whispers intention, mysterious, complete]</td>\n",
              "      <td>[whispers intention, mysterious, complete]</td>\n",
              "      <td>[whispers intention, mysterious, cryptic, cryp...</td>\n",
              "      <td>whispers intention mysterious cryptic cryptica...</td>\n",
              "      <td>0.105492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... sim_score\n",
              "270  270  ...  0.751439\n",
              "469  469  ...  0.679702\n",
              "65    65  ...  0.600545\n",
              "28    28  ...  0.543852\n",
              "16    16  ...  0.502939\n",
              "196  196  ...  0.245040\n",
              "537  537  ...  0.153213\n",
              "476  476  ...  0.118678\n",
              "132  132  ...  0.106819\n",
              "222  222  ...  0.105492\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 480
        }
      ]
    }
  ]
}